{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "import os\n",
    "import matplotlib.pyplot as mp\n",
    "\n",
    "# Import tools for keras.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ParserUtils' from 'C:\\\\Users\\\\micha\\\\Documents\\\\CS101\\\\seis-GAN\\\\ParserUtils.py'>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imp import reload\n",
    "import TensorFlowUtils\n",
    "reload(TensorFlowUtils)\n",
    "import SeisUtils\n",
    "reload(SeisUtils)\n",
    "import ProgressiveGAN\n",
    "reload(ProgressiveGAN)\n",
    "import GAN\n",
    "reload(GAN)\n",
    "import ModelBase\n",
    "reload(ModelBase)\n",
    "import GANModel\n",
    "reload(GANModel)\n",
    "import ParserUtils\n",
    "reload(ParserUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TensorFlowUtils import show_graph\n",
    "from SeisUtils       import extract_func\n",
    "from SeisUtils       import SeisData\n",
    "from SeisUtils       import SeisGenerator\n",
    "from GAN             import GAN\n",
    "from ModelBase       import ModelBase\n",
    "from GANModel        import GANModel\n",
    "from ParserUtils     import ArgModelParser\n",
    "from ProgressiveGAN  import ProgressiveGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_d = {\n",
    "    \n",
    "    #---------\n",
    "    # Data\n",
    "    #---------\n",
    "    \n",
    "    'data_path'   : 'wformMat_jpm4p_181106_downsample-5x.h5', # path to data\n",
    "    'data_format' : 'channels_last', # data format ('channels_first' or 'channels_last')\n",
    "    'train_frac'  : 0.0001,  # % of data devoted to Training\n",
    "    \n",
    "    #---------\n",
    "    # Wforms\n",
    "    #---------\n",
    "\n",
    "    'burn_seconds'                 : 2.5,   # first  part of wform to throw away\n",
    "    'input_seconds'                : 80,    # middle part of waveform to use as input\n",
    "    'output_seconds'               : None,  # last   part of waveform to use as target output or None if generting x.\n",
    "    'measure_rate'                 : 20,    # sampling rate in HZ\n",
    "    'normalize_data'               : True,  # whether to normalize input waveforms to lie between -1 and 1.\n",
    "    'predict_normalization_factor' : True, # whether to predict the normalization factor if computed\n",
    "\n",
    "    #---------\n",
    "    # Training\n",
    "    #---------\n",
    "    \n",
    "    'batch_size'  : 4, # batch size\n",
    "    'epochs'      : 2, # training epochs\n",
    "    'random_seed' : 7, # random seed\n",
    "    'metas'       : ['dist', 'magn'], # meta to include as conditional parameters.\n",
    "    'weight_loss' : False, \n",
    "    \"conditional_config\"    : {\"one_hot_encode\": True, \"aux_classify\": False},\n",
    "    \"bins_s\"                : [10, [0, 3, 4, 5, 6, 7, 8, \"inf\"]],\n",
    "    \n",
    "    #--------\n",
    "    # Saving\n",
    "    #--------\n",
    "    \n",
    "    'directory'   : 'TEST', # defaults to todays date. Will make a dir called 'GAN_<directory>\n",
    "    'restore'     : False,\n",
    "    \n",
    "    #--------\n",
    "    # Debug\n",
    "    #--------\n",
    "\n",
    "    'debug' : True,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config {'data_path': 'wformMat_jpm4p_181106_downsample-5x.h5', 'data_format': 'channels_last', 'train_frac': 0.0001, 'burn_seconds': 2.5, 'input_seconds': 80, 'output_seconds': None, 'measure_rate': 20, 'normalize_data': True, 'predict_normalization_factor': True, 'batch_size': 4, 'epochs': 2, 'random_seed': 7, 'metas': ['dist', 'magn'], 'weight_loss': False, 'conditional_config': {'one_hot_encode': True, 'aux_classify': False}, 'bins_s': [10, [0, 3, 4, 5, 6, 7, 8, 'inf']], 'directory': 'TEST', 'restore': False, 'debug': True}\n",
      "Testing    Samples: 144855\n",
      "Validation Samples: 115884\n",
      "Training   Samples: 25 \n",
      "\n",
      "conditional_metav (shape): [(260764, 10), (260764, 7)]\n",
      "weights: [0.7495804 1.4531128 1.4531128 ... 2.3466036 2.3466036 2.3466036]\n",
      "   max  =  5014.6924\n",
      "   min  =  0.084483586\n",
      "   mean =  0.9999999\n",
      "   std  =  12.046692 \n",
      "\n",
      "Testing    Samples: 36214\n",
      "Validation Samples: 28971\n",
      "Training   Samples: 6\n",
      "Generator.call() training = Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, 100, 3)\n",
      "\n",
      "dense_1: units = 200\n",
      "     x.shape (?, 100, 200)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"generator/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"generator/Tile:0\", shape=(?, 17, 3), dtype=float32, device=/device:GPU:0) (?, 17, 3)\n",
      "     added_conditional\n",
      "     x.shape (?, 117, 3)\n",
      "\n",
      "transpose: perm = ListWrapper([0, 2, 1])\n",
      "     x.shape (?, 3, 117)\n",
      "dense_2: units = 200\n",
      "     x.shape (?, 3, 200)\n",
      "batch_normalization: axis = ListWrapper([1])\n",
      "     x.shape (?, 3, 200)\n",
      "transpose_1: perm = ListWrapper([0, 2, 1])\n",
      "     x.shape (?, 200, 3)\n",
      "expand_dim: axis = 2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "conv2d_1: filters = 3 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "batch_normalization_1: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 3)\n",
      "re_lu\n",
      "     x.shape (?, 200, 1, 3)\n",
      "conv2d_2: filters = 6 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 6)\n",
      "batch_normalization_2: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 6)\n",
      "re_lu_1\n",
      "     x.shape (?, 200, 1, 6)\n",
      "conv2d_3: filters = 3 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "batch_normalization_3: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 3)\n",
      "re_lu_2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_2: perm = ListWrapper([0, 2, 1])\n",
      "     x.shape (?, 3, 200)\n",
      "dense_3: units = 401\n",
      "     x.shape (?, 3, 401)\n",
      "batch_normalization_4: axis = ListWrapper([1])\n",
      "     x.shape (?, 3, 400)\n",
      "re_lu_3\n",
      "     x.shape (?, 3, 400)\n",
      "reshape: shape = (-1, 100, 1, 12)\n",
      "     x.shape (?, 100, 1, 12)\n",
      "to_sample_1: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 100, 1, 3)\n",
      "tanh\n",
      "     x.shape (?, 100, 1, 3)\n",
      "squeeze_5: axis = 2\n",
      "     x.shape (?, 100, 3)\n",
      "transpose_3: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 100, 3)\n",
      "to_sample_1: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 100, 1, 3)\n",
      "tanh\n",
      "     x.shape (?, 100, 1, 3)\n",
      "squeeze_5: axis = 2\n",
      "     x.shape (?, 100, 3)\n",
      "transpose_3: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 100, 3)\n",
      "expand_dim_1: axis = 2\n",
      "     x.shape (?, 100, 1, 3)\n",
      "resize: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_1: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "to_sample_2: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "tanh_1\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_6: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_4: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 200, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "to_sample_2: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "tanh_1\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_6: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_4: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 200, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "to_sample_2: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "tanh_1\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_6: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_4: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 200, 3)\n",
      "expand_dim_2: axis = 2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "resize_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_2: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "to_sample_3: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 3)\n",
      "tanh_2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_7: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "transpose_5: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 400, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "to_sample_3: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 3)\n",
      "tanh_2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_7: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "transpose_5: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 400, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "to_sample_3: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 3)\n",
      "tanh_2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_7: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "transpose_5: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 400, 3)\n",
      "expand_dim_3: axis = 2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "resize_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_3: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "to_sample_4: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 3)\n",
      "tanh_3\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_8: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "transpose_6: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 800, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "to_sample_4: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 3)\n",
      "tanh_3\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_8: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "transpose_6: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 800, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "to_sample_4: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 3)\n",
      "tanh_3\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_8: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "transpose_6: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 800, 3)\n",
      "expand_dim_4: axis = 2\n",
      "     x.shape (?, 800, 1, 3)\n",
      "resize_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_4: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "resize_nearest_neighbor_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 32)\n",
      "conv2d_10: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_11: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_10\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "conv2d_11: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_12: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_11\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "to_sample_5: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 3)\n",
      "tanh_4\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_9: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "transpose_7: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 1600, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "resize_nearest_neighbor_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 32)\n",
      "conv2d_10: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_11: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_10\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "conv2d_11: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_12: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_11\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "to_sample_5: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 3)\n",
      "tanh_4\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_9: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "transpose_7: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 1600, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "resize_nearest_neighbor_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 32)\n",
      "conv2d_10: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_11: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_10\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "conv2d_11: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_12: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_11\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "to_sample_5: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 3)\n",
      "tanh_4\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_9: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "transpose_7: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 1600, 3)\n",
      "Generator.call() training = False\n",
      "     x.shape (?, 100, 3)\n",
      "\n",
      "dense_1: units = 200\n",
      "     x.shape (?, 100, 200)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"generator_1/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"generator_1/Tile:0\", shape=(?, 17, 3), dtype=float32, device=/device:GPU:0) (?, 17, 3)\n",
      "     added_conditional\n",
      "     x.shape (?, 117, 3)\n",
      "\n",
      "transpose: perm = ListWrapper([0, 2, 1])\n",
      "     x.shape (?, 3, 117)\n",
      "dense_2: units = 200\n",
      "     x.shape (?, 3, 200)\n",
      "batch_normalization: axis = ListWrapper([1])\n",
      "     x.shape (?, 3, 200)\n",
      "transpose_1: perm = ListWrapper([0, 2, 1])\n",
      "     x.shape (?, 200, 3)\n",
      "expand_dim: axis = 2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "conv2d_1: filters = 3 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "batch_normalization_1: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 3)\n",
      "re_lu\n",
      "     x.shape (?, 200, 1, 3)\n",
      "conv2d_2: filters = 6 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 6)\n",
      "batch_normalization_2: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 6)\n",
      "re_lu_1\n",
      "     x.shape (?, 200, 1, 6)\n",
      "conv2d_3: filters = 3 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "batch_normalization_3: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 3)\n",
      "re_lu_2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_2: perm = ListWrapper([0, 2, 1])\n",
      "     x.shape (?, 3, 200)\n",
      "dense_3: units = 401\n",
      "     x.shape (?, 3, 401)\n",
      "batch_normalization_4: axis = ListWrapper([1])\n",
      "     x.shape (?, 3, 400)\n",
      "re_lu_3\n",
      "     x.shape (?, 3, 400)\n",
      "reshape: shape = (-1, 100, 1, 12)\n",
      "     x.shape (?, 100, 1, 12)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_5: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = ListWrapper([3])\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_7: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = ListWrapper([3])\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_9: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = ListWrapper([3])\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "resize_nearest_neighbor_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 32)\n",
      "conv2d_10: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_11: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_10\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "conv2d_11: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_12: axis = ListWrapper([3])\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_11\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "to_sample_5: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 3)\n",
      "tanh_4\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_9: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "transpose_7: perm = ListWrapper([0, 1, 2])\n",
      "     x.shape (?, 1600, 3)\n",
      "Discriminator.call() False\n",
      "     x.shape (?, 100, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, 100, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, 117, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, 120, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat_6:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_4:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_5:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_1/progressive_discriminator/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_1/progressive_discriminator/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat_6:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_4:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_5:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_2/progressive_discriminator/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"generator/progressive_generator/cond/Merge_1:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_2/progressive_discriminator/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat_3:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_2:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_3:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/concat_6:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_4:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/case/cond/cond/cond/cond/cond/cond/cond/cond/Tile_5:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Discriminator.call() Tensor(\"training_bool:0\", shape=(), dtype=bool, device=/device:GPU:0)\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/cond/concat:0\", shape=(?, 17), dtype=float32, device=/device:GPU:0) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_3/progressive_discriminator/cond/Tile:0\", shape=(?, 17, 32), dtype=float32, device=/device:GPU:0) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_3:0\", shape=(?, 3), dtype=float32, device=/device:GPU:0) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_3/progressive_discriminator/cond/Tile_1:0\", shape=(?, 3, 32), dtype=float32, device=/device:GPU:0) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              multiple                  600       \n",
      "_________________________________________________________________\n",
      "transpose (Transpose)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  23400     \n",
      "_________________________________________________________________\n",
      "transpose_1 (Transpose)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "expand_dim (ExpandDim)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  147       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  12        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  294       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  24        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  291       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  12        \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "squeeze (Squeeze)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "transpose_2 (Transpose)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  80200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  12        \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "block (Block)                multiple                  5952      \n",
      "_________________________________________________________________\n",
      "block_1 (Block)              multiple                  25216     \n",
      "_________________________________________________________________\n",
      "block_2 (Block)              multiple                  12608     \n",
      "_________________________________________________________________\n",
      "block_3 (Block)              multiple                  3232      \n",
      "_________________________________________________________________\n",
      "resize (Resize)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "resize_1 (Resize)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "resize_2 (Resize)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "resize_3 (Resize)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "to_sample_1 (ToSample)       multiple                  39        \n",
      "_________________________________________________________________\n",
      "to_sample_2 (ToSample)       multiple                  99        \n",
      "_________________________________________________________________\n",
      "to_sample_3 (ToSample)       multiple                  195       \n",
      "_________________________________________________________________\n",
      "to_sample_4 (ToSample)       multiple                  99        \n",
      "_________________________________________________________________\n",
      "to_sample_5 (ToSample)       multiple                  51        \n",
      "=================================================================\n",
      "Total params: 152,495\n",
      "Trainable params: 151,883\n",
      "Non-trainable params: 612\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block_4 (Block)              multiple                  1248      \n",
      "_________________________________________________________________\n",
      "block_5 (Block)              multiple                  6208      \n",
      "_________________________________________________________________\n",
      "block_6 (Block)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "block_7 (Block)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "from_sample_1 (FromSample)   multiple                  12        \n",
      "_________________________________________________________________\n",
      "from_sample_2 (FromSample)   multiple                  64        \n",
      "_________________________________________________________________\n",
      "from_sample_3 (FromSample)   multiple                  128       \n",
      "_________________________________________________________________\n",
      "from_sample_4 (FromSample)   multiple                  128       \n",
      "_________________________________________________________________\n",
      "from_sample_5 (FromSample)   multiple                  128       \n",
      "_________________________________________________________________\n",
      "squeeze_14 (Squeeze)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "transpose_8 (Transpose)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  36300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  45150     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  22650     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  4801      \n",
      "=================================================================\n",
      "Total params: 133,329\n",
      "Trainable params: 133,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gm = GANModel(config_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 1\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 1\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 1\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 1\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 1\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Time taken for epoch 1 is 60.87727475166321 sec\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 7\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 7\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 7\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 7\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "     ... Saving summaries at global step: 7\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n",
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n",
      "Time taken for epoch 2 is 8.918160915374756 sec\n"
     ]
    }
   ],
   "source": [
    "# %%pixie_debugger\n",
    "gm.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show tf graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_graph(gm.graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to run specific training ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting   randomly sampled batch\n",
      "Retreived randomly sampled batch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4, 1600, 3), (4, 100, 3))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get batch of data.\n",
    "batch = gm.SG_train.random_batch()\n",
    "wform_x = batch.x\n",
    "batch.x.shape, gm.noise().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get global step.\n",
    "with gm.sess.as_default():\n",
    "    with gm.graph.as_default():\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "gs_assign   = global_step.assign(13000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_dict(training = True):\n",
    "    feed_dict = {gm.gen_input_placeholder : gm.noise(), \"real_input:0\" : wform_x, gm.training_bool_placeholder : training} #gm.dis_input_placeholder : wform_x}\n",
    "    if gm.conditional_placeholders is not None:\n",
    "        feed_dict.update({cp : m for cp, m in zip(gm.conditional_placeholders, batch.metav if isinstance(batch.metav, list) else batch.metav)})\n",
    "    if gm.weights_placeholder is not None:\n",
    "        feed_dict[gm.weights_placeholder]        = batch.weights[:, None]\n",
    "    if gm.pred_norm_real_placeholder is not None:\n",
    "        feed_dict[gm.pred_norm_real_placeholder] = batch.x_normalization\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data0 = gm.sess.run( [gs_assign, gm.gen_output_tensor], feed_dict = feed_dict(training = True)\n",
    "# data1a  = gm.sess.run( [gs_assign, gm.dis_input_tensor], feed_dict = feed_dict(training = True)\n",
    "# data1b  = gm.sess.run( [gs_assign, gm.dis_output_real_tensor], feed_dict = feed_dict(training = True)\n",
    "# data1c  = gm.sess.run( [gs_assign, gm.dis_output_fake_tensor], feed_dict = feed_dict(training = True)\n",
    "\n",
    "# data2 = gm.sess.run( [gs_assign, gm.mixed_input_data], feed_dict = feed_dict())\n",
    "# data3 = gm.sess.run( [gs_assign, gm.mixed_output], feed_dict = feed_dict())\n",
    "# data4 = gm.sess.run( [gs_assign, gm.dis_loss_tensor], feed_dict = feed_dict())\n",
    "# data5 = gm.sess.run( [gs_assign, gm.dis_calc_grads_op], feed_dict = feed_dict())\n",
    "data6 = gm.sess.run( [gs_assign, gm.dis_apply_grads_op], feed_dict = feed_dict())\n",
    "data7 = gm.sess.run( [gs_assign, gm.gen_apply_grads_op], feed_dict = feed_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Foward pass when training isn't on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1: units = 200\n",
      "     x.shape (?, 100, 200)\n",
      "x_to_samp Tensor(\"generator/to_sample/transpose_7_3/transpose:0\", shape=(?, 1600, 3), dtype=float32)\n",
      "last_block\n",
      "<function Discriminator.call at 0x000002826D6CF0D0>\n",
      "[<tf.Tensor 'discriminator_4/block_7/leaky_re_lu_7/LeakyRelu:0' shape=(?, 100, 1, 32) dtype=float32>] {'training': False, 'conditional': [<tf.Tensor 'conditional:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'conditional_1:0' shape=(?, 7) dtype=float32>], 'pred_norm': <tf.Tensor 'Placeholder:0' shape=(?, 3) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "with gm.sess.as_default():\n",
    "    with gm.graph.as_default():\n",
    "        gen_out_training_false = gm.generator    (gm.gen_input_placeholder, training = False, conditional = gm.conditional_placeholders).data\n",
    "        dis_out_training_false = gm.discriminator(gen_out_training_false  , training = False, conditional = gm.conditional_placeholders, pred_norm = gm.pred_norm_real_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gm.sess.run(dis_out_training_false, feed_dict = feed_dict(training = False))\n",
    "data.score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to run progressive tracking tesors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000, 10000, 5, True, False, 0.0]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gm.sess.as_default():\n",
    "    with gm.graph.as_default():\n",
    "        initial_steps_placeholder, stabilizing_steps_placeholder, stage_int_tensor, fade_phase_bool, alpha_tensor = ProgressiveGAN.get_or_create_tracking_tensors()\n",
    "        predicate = (stage_int_tensor <= 0) & tf.equal(fade_phase_bool, tf.constant(False))\n",
    "gm.sess.run([initial_steps_placeholder, stabilizing_steps_placeholder, stage_int_tensor, fade_phase_bool, predicate, alpha_tensor], feed_dict = {global_step : 90000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to compute grads of mixed output when training is False (i.e. no progressive tensors will be used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator.call() training = True\n",
      "     x.shape (?, 100, 3)\n",
      "\n",
      "dense_1: units = 200\n",
      "     x.shape (?, 100, 200)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"generator_4/concat:0\", shape=(?, 17), dtype=float32) (?, 17)\n",
      "     conditional: Tensor(\"generator_4/Tile:0\", shape=(?, 17, 3), dtype=float32) (?, 17, 3)\n",
      "     added_conditional\n",
      "     x.shape (?, 117, 3)\n",
      "\n",
      "transpose: perm = [0, 2, 1]\n",
      "     x.shape (?, 3, 117)\n",
      "dense_2: units = 200\n",
      "     x.shape (?, 3, 200)\n",
      "batch_normalization_1: axis = [1]\n",
      "     x.shape (?, 3, 200)\n",
      "transpose_1: perm = [0, 2, 1]\n",
      "     x.shape (?, 200, 3)\n",
      "expand_dim: axis = 2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "conv2d_1: filters = 3 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "batch_normalization_2: axis = [3]\n",
      "     x.shape (?, 200, 1, 3)\n",
      "re_lu\n",
      "     x.shape (?, 200, 1, 3)\n",
      "conv2d_2: filters = 6 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 6)\n",
      "batch_normalization_3: axis = [3]\n",
      "     x.shape (?, 200, 1, 6)\n",
      "re_lu_1\n",
      "     x.shape (?, 200, 1, 6)\n",
      "conv2d_3: filters = 3 // kernel_size = (16, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "batch_normalization_4: axis = [3]\n",
      "     x.shape (?, 200, 1, 3)\n",
      "re_lu_2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_2: perm = [0, 2, 1]\n",
      "     x.shape (?, 3, 200)\n",
      "dense_3: units = 401\n",
      "     x.shape (?, 3, 401)\n",
      "batch_normalization_5: axis = [1]\n",
      "     x.shape (?, 3, 400)\n",
      "re_lu_3\n",
      "     x.shape (?, 3, 400)\n",
      "reshape: shape = (-1, 100, 1, 12)\n",
      "     x.shape (?, 100, 1, 12)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_11: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "resize_nearest_neighbor_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 32)\n",
      "conv2d_10: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_12: axis = [3]\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_10\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "conv2d_11: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_13: axis = [3]\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_11\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "to_sample_5: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 3)\n",
      "tanh_4\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_9: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "transpose_7: perm = [0, 1, 2]\n",
      "     x.shape (?, 1600, 3)\n",
      "x_to_samp Tensor(\"generator/to_sample/transpose_7_6/transpose:0\", shape=(?, 1600, 3), dtype=float32)\n",
      "to_sample_1: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 100, 1, 3)\n",
      "tanh\n",
      "     x.shape (?, 100, 1, 3)\n",
      "squeeze_5: axis = 2\n",
      "     x.shape (?, 100, 3)\n",
      "transpose_3: perm = [0, 1, 2]\n",
      "     x.shape (?, 100, 3)\n",
      "to_sample_1: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 100, 1, 3)\n",
      "tanh\n",
      "     x.shape (?, 100, 1, 3)\n",
      "squeeze_5: axis = 2\n",
      "     x.shape (?, 100, 3)\n",
      "transpose_3: perm = [0, 1, 2]\n",
      "     x.shape (?, 100, 3)\n",
      "expand_dim_1: axis = 2\n",
      "     x.shape (?, 100, 1, 3)\n",
      "resize: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_1: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "to_sample_2: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "tanh_1\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_6: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_4: perm = [0, 1, 2]\n",
      "     x.shape (?, 200, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "to_sample_2: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "tanh_1\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_6: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_4: perm = [0, 1, 2]\n",
      "     x.shape (?, 200, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "to_sample_2: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 3)\n",
      "tanh_1\n",
      "     x.shape (?, 200, 1, 3)\n",
      "squeeze_6: axis = 2\n",
      "     x.shape (?, 200, 3)\n",
      "transpose_4: perm = [0, 1, 2]\n",
      "     x.shape (?, 200, 3)\n",
      "expand_dim_2: axis = 2\n",
      "     x.shape (?, 200, 1, 3)\n",
      "resize_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_2: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "to_sample_3: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 3)\n",
      "tanh_2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_7: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "transpose_5: perm = [0, 1, 2]\n",
      "     x.shape (?, 400, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "to_sample_3: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 3)\n",
      "tanh_2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_7: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "transpose_5: perm = [0, 1, 2]\n",
      "     x.shape (?, 400, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "to_sample_3: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 3)\n",
      "tanh_2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "squeeze_7: axis = 2\n",
      "     x.shape (?, 400, 3)\n",
      "transpose_5: perm = [0, 1, 2]\n",
      "     x.shape (?, 400, 3)\n",
      "expand_dim_3: axis = 2\n",
      "     x.shape (?, 400, 1, 3)\n",
      "resize_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_3: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_11: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "to_sample_4: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 3)\n",
      "tanh_3\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_8: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "transpose_6: perm = [0, 1, 2]\n",
      "     x.shape (?, 800, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_11: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "to_sample_4: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 3)\n",
      "tanh_3\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_8: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "transpose_6: perm = [0, 1, 2]\n",
      "     x.shape (?, 800, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_11: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "to_sample_4: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 3)\n",
      "tanh_3\n",
      "     x.shape (?, 800, 1, 3)\n",
      "squeeze_8: axis = 2\n",
      "     x.shape (?, 800, 3)\n",
      "transpose_6: perm = [0, 1, 2]\n",
      "     x.shape (?, 800, 3)\n",
      "expand_dim_4: axis = 2\n",
      "     x.shape (?, 800, 1, 3)\n",
      "resize_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_4: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "resize_nearest_neighbor: scale = (2, 1)\n",
      "     x.shape (?, 200, 1, 12)\n",
      "conv2d_4: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_6: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_4\n",
      "     x.shape (?, 200, 1, 32)\n",
      "conv2d_5: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 200, 1, 32)\n",
      "batch_normalization_7: axis = [3]\n",
      "     x.shape (?, 200, 1, 32)\n",
      "re_lu_5\n",
      "     x.shape (?, 200, 1, 32)\n",
      "resize_nearest_neighbor_1: scale = (2, 1)\n",
      "     x.shape (?, 400, 1, 32)\n",
      "conv2d_6: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_8: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_6\n",
      "     x.shape (?, 400, 1, 64)\n",
      "conv2d_7: filters = 64 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 400, 1, 64)\n",
      "batch_normalization_9: axis = [3]\n",
      "     x.shape (?, 400, 1, 64)\n",
      "re_lu_7\n",
      "     x.shape (?, 400, 1, 64)\n",
      "resize_nearest_neighbor_2: scale = (2, 1)\n",
      "     x.shape (?, 800, 1, 64)\n",
      "conv2d_8: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_10: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_8\n",
      "     x.shape (?, 800, 1, 32)\n",
      "conv2d_9: filters = 32 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 800, 1, 32)\n",
      "batch_normalization_11: axis = [3]\n",
      "     x.shape (?, 800, 1, 32)\n",
      "re_lu_9\n",
      "     x.shape (?, 800, 1, 32)\n",
      "resize_nearest_neighbor_3: scale = (2, 1)\n",
      "     x.shape (?, 1600, 1, 32)\n",
      "conv2d_10: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_12: axis = [3]\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_10\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "conv2d_11: filters = 16 // kernel_size = (4, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 16)\n",
      "batch_normalization_13: axis = [3]\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "re_lu_11\n",
      "     x.shape (?, 1600, 1, 16)\n",
      "to_sample_5: filters = 3 // kernel_size = (1, 1) // strides = (1, 1) \n",
      "     x.shape (?, 1600, 1, 3)\n",
      "tanh_4\n",
      "     x.shape (?, 1600, 1, 3)\n",
      "squeeze_9: axis = 2\n",
      "     x.shape (?, 1600, 3)\n",
      "transpose_7: perm = [0, 1, 2]\n",
      "     x.shape (?, 1600, 3)\n",
      "last_block\n",
      "[<tf.Tensor 'discriminator_6/block_7/leaky_re_lu_7/LeakyRelu:0' shape=(?, ?, 1, 32) dtype=float32>] {'training': False, 'conditional': [<tf.Tensor 'conditional:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'conditional_1:0' shape=(?, 7) dtype=float32>], 'pred_norm': <tf.Tensor 'add_10:0' shape=(?, 3) dtype=float32>}\n",
      "Discriminator.call() False\n",
      "     x.shape (?, ?, 1, 32)\n",
      "squeeze_14: axis = 2\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Conditional:\n",
      "     conditional: Tensor(\"discriminator_6/concat:0\", shape=(?, 17), dtype=float32) (?, 17)\n",
      "     conditional: Tensor(\"discriminator_6/Tile:0\", shape=(?, 17, 32), dtype=float32) (?, 17, 32)\n",
      "     appended conditional\n",
      "     x.shape (?, ?, 32)\n",
      "Appending Predicted Norm:\n",
      "     pred_norm: Tensor(\"add_10:0\", shape=(?, 3), dtype=float32) (?, 3)\n",
      "     pred_norm: Tensor(\"discriminator_6/Tile_1:0\", shape=(?, 3, 32), dtype=float32) (?, 3, 32)\n",
      "     appended predicted norm\n",
      "     x.shape (?, ?, 32)\n",
      "dense_4: units = 300\n",
      "     x.shape (?, 32, 300)\n",
      "leaky_re_lu_8\n",
      "     x.shape (?, 32, 300)\n",
      "dense_5: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_9\n",
      "     x.shape (?, 32, 150)\n",
      "dense_6: units = 150\n",
      "     x.shape (?, 32, 150)\n",
      "leaky_re_lu_10\n",
      "     x.shape (?, 32, 150)\n",
      "flatten_1\n",
      "     x.shape (?, 4800)\n",
      "dense_7: units = 1\n",
      "     x.shape (?, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [4,1600,3] vs. [4,100,3]\n\t [[node add_9 (defined at <ipython-input-114-159af2f8b2a4>:10) ]]\n\nCaused by op 'add_9', defined at:\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-114-159af2f8b2a4>\", line 10, in <module>\n    mixed_input_data      = (epsilon * gm.dis_input_placeholder     ) + (1 - epsilon) * gen_output_tensor\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 812, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 374, in add\n    \"Add\", x=x, y=y, name=name)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [4,1600,3] vs. [4,100,3]\n\t [[node add_9 (defined at <ipython-input-114-159af2f8b2a4>:10) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4,1600,3] vs. [4,100,3]\n\t [[{{node add_9}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-159af2f8b2a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmix_calc_grads_op_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixed_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmixed_input_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mgm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmix_calc_grads_op_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4,1600,3] vs. [4,100,3]\n\t [[node add_9 (defined at <ipython-input-114-159af2f8b2a4>:10) ]]\n\nCaused by op 'add_9', defined at:\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-114-159af2f8b2a4>\", line 10, in <module>\n    mixed_input_data      = (epsilon * gm.dis_input_placeholder     ) + (1 - epsilon) * gen_output_tensor\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 812, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 374, in add\n    \"Add\", x=x, y=y, name=name)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"c:\\users\\micha\\envs\\seis3.6.7\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [4,1600,3] vs. [4,100,3]\n\t [[node add_9 (defined at <ipython-input-114-159af2f8b2a4>:10) ]]\n"
     ]
    }
   ],
   "source": [
    "with gm.graph.as_default():\n",
    "    \n",
    "    with gm.sess.as_default():\n",
    "\n",
    "        gen_output = gm.generator(gm.gen_input_placeholder, training = True, conditional = gm.conditional_placeholders)\n",
    "        gen_output_tensor     = gen_output.data\n",
    "        pred_norm_fake_tensor = gen_output.pred_norm\n",
    "\n",
    "        epsilon               = tf.random_uniform([], 0, 1)\n",
    "        mixed_input_data      = (epsilon * gm.dis_input_placeholder     ) + (1 - epsilon) * gen_output_tensor\n",
    "        mixed_input_pred_norm = (epsilon * gm.pred_norm_real_placeholder) + (1 - epsilon) * pred_norm_fake_tensor if pred_norm_fake_tensor is not None else None\n",
    "        mixed_output          = gm.discriminator(mixed_input_data, training = False, conditional = gm.conditional_placeholders, pred_norm = mixed_input_pred_norm).score\n",
    "\n",
    "        mix_calc_grads_op_data = gm.discriminator_optimizer.compute_gradients(mixed_output, mixed_input_data)\n",
    "\n",
    "        gm.sess.run(mix_calc_grads_op_data, feed_dict = feed_dict())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to compute gen loss tensors and grad tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting   randomly sampled metav.\n",
      "Retreived randomly sampled metav.\n"
     ]
    }
   ],
   "source": [
    "batch   = gm.SG_train.random_metav()\n",
    "\n",
    "feed_dict = {gm.gen_input_placeholder : gm.noise()}\n",
    "if gm.conditional_placeholders is not None:\n",
    "    feed_dict.update({cp : m for cp, m in zip(gm.conditional_placeholders, batch.metav if isinstance(batch.metav, list) else batch.metav)})\n",
    "if gm.weights_placeholder is not None:\n",
    "    feed_dict[gm.weights_placeholder]     = batch.weights[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gm.sess.run([gm.gen_calc_grads_op], feed_dict = feed_dict)\n",
    "# gm.sess.run(gm.generator_optimizer.compute_gradients(gm.gen_output_tensor,  gm.generator.variables), feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_calc_grads_op = gm.generator_optimizer.compute_gradients(gm.gen_output_tensor,  gm.generator.variables)\n",
    "\n",
    "# Remove null gradients.\n",
    "gen_grads_idx       = [i for i, g_op in enumerate(gen_calc_grads_op) if g_op[0] is not None]\n",
    "generator_variables = [gen_calc_grads_op[i][1] for i in gen_grads_idx]\n",
    "gen_calc_grads_op   = [gen_calc_grads_op[i][0] for i in gen_grads_idx]\n",
    "\n",
    "# Clip gradients.\n",
    "if gm.config.get('clip_gen_grad_norm'):\n",
    "    gen_calc_grads_op = [g_op for g_op in gen_calc_grads_op if g_op[0] is not None] if isinstance(gen_calc_grads_op, list) else gen_calc_grads_op\n",
    "    gen_calc_grads_op, gen_grads_global_norm = tf.clip_by_global_norm(gen_calc_grads_op, gm.config['clip_gen_grad_norm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gm.sess.run(gen_calc_grads_op, feed_dict = feed_dict) # This works, so grads through the progressive gen are 'A-ok =b'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
